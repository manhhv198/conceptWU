import re
import requests
import google.generativeai as genai
from PIL import Image, UnidentifiedImageError
from io import BytesIO
import os
import time
import sys
import xml.etree.ElementTree as ET

# Force UTF-8 logging so emojis don't crash Windows terminals
sys.stdout.reconfigure(encoding='utf-8')

# --- C·∫§U H√åNH ---
# 1. API Key Gemini
# Prefer environment variable, fallback to placeholder or user input
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "AIzaSyAAr00S3VxBdwXHJZYtji-VMW6gBCulxR8")
genai.configure(api_key=GEMINI_API_KEY)
model = genai.GenerativeModel('gemini-2.5-flash')

# 2. Jina Reader Endpoint (D√πng mi·ªÖn ph√≠, kh√¥ng c·∫ßn key cho m·ª©c ƒë·ªô c∆° b·∫£n)
JINA_READER_URL = "https://r.jina.ai/"

# Global Token Counters
token_usage = {
    "jina": {"in": 0, "out": 0},
    "gemini": {"in": 0, "out": 0}
}

def get_text_from_jina(target_url):
    """G·ªçi Jina ƒë·ªÉ l·∫•y n·ªôi dung Markdown s·∫°ch (c√≥ Retry)"""
    print(f"1Ô∏è‚É£  ƒêang g·ªçi Jina Reader ƒë·ªÉ l·∫•y vƒÉn b·∫£n: {target_url}")
    headers = {
        'X-Return-Format': 'html',
        # Target Selector: M·ªü r·ªông ƒë·ªÉ b·∫Øt c√°c class bi·ªÉu ƒë·ªì ph·ªï bi·∫øn nh∆∞ Highcharts, canvas, svg
        'X-Target-Selector': 'article, main, .main, #main, .content, #content, .post, .entry, table, figure, img, .chart, .graph, .highcharts-container, .highcharts-root, svg, canvas',
        # Remove Selector: Gi·ªØ nguy√™n nh∆∞ng ƒë·∫£m b·∫£o kh√¥ng x√≥a nh·∫ßm class ch·ª©a chart
        'X-Remove-Selector': 'header, footer, nav, aside, .menu, .sidebar, .ad, .advertisement, .related, .comments, .cookie-banner, .popup, .highcharts-credits',
        'X-WaitFor-Selector': '.highcharts-root' # Ch·ªù chart t·∫£i xong
    }
    
    max_retries = 3
    for attempt in range(max_retries):
        try:
            response = requests.get(JINA_READER_URL + target_url, headers=headers, timeout=60) # TƒÉng timeout client l√™n 60s
            
            if response.status_code == 200:
                # Jina kh√¥ng tr·∫£ token usage trong header chu·∫©n, ta ∆∞·ªõc l∆∞·ª£ng ho·∫∑c l·∫•y t·ª´ header n·∫øu sau n√†y c√≥ update
                # Input: URL length (∆∞·ªõc l∆∞·ª£ng th√¥)
                token_usage["jina"]["in"] += len(target_url) 
                # Output: Content length
                token_usage["jina"]["out"] += len(response.text)
                
                return response.text
            elif response.status_code == 524 or response.status_code >= 500:
                print(f"   ‚ö†Ô∏è L·ªói server Jina ({response.status_code}). ƒêang th·ª≠ l·∫°i ({attempt + 1}/{max_retries})...")
                time.sleep(3) # ƒê·ª£i 3s tr∆∞·ªõc khi th·ª≠ l·∫°i
            else:
                print(f"‚ùå L·ªói Jina: {response.status_code}")
                return None
                
        except requests.exceptions.Timeout:
            print(f"   ‚ö†Ô∏è Timeout k·∫øt n·ªëi (Client). ƒêang th·ª≠ l·∫°i ({attempt + 1}/{max_retries})...")
            time.sleep(3)
        except Exception as e:
            print(f"‚ùå L·ªói k·∫øt n·ªëi Jina: {e}")
            return None
            
    print("‚ùå Th·∫•t b·∫°i sau nhi·ªÅu l·∫ßn th·ª≠.")
    return None

# ... (images code unchanged) ...

def process_content_hybrid(url):
    # B∆∞·ªõc 1: L·∫•y Text s·∫°ch t·ª´ Jina
    markdown_content = get_text_from_jina(url)
    if not markdown_content:
        return []

    print("2Ô∏è‚É£  ƒêang x·ª≠ l√Ω n·ªôi dung v√† qu√©t ·∫£nh...")
    
    # Regex ph√°t hi·ªán ·∫£nh: ![alt](url)
    image_pattern = re.compile(r'!\[.*?\]\((https?://.*?)\)')
    
    # Regex ƒë·ªÉ lo·∫°i b·ªè link [text](url) -> gi·ªØ l·∫°i text
    # Negative lookbehind (?<!!) ƒë·∫£m b·∫£o kh√¥ng match ![...] (·∫£nh)
    link_pattern = re.compile(r'(?<!!)\[([^\]]+)\]\([^\)]+\)')
    
    labeled_data = [] # List of tuples: (type, content) -> ("TEXT", "...") or ("IMAGE", "...")

    # T√°ch d√≤ng ƒë·ªÉ x·ª≠ l√Ω t·ª´ng ph·∫ßn
    lines = markdown_content.split('\n')
    
    # --- Jina ƒë√£ l·ªçc b·∫±ng Selector n√™n kh√¥ng c·∫ßn extract_main_body qu√° g·∫Øt gao n·ªØa ---
    # lines = extract_main_body(lines) 
    # Nh∆∞ng v·∫´n g·ªçi ƒë·ªÉ lo·∫°i b·ªè ph·∫ßn th·ª´a n·∫øu Jina s√≥t (v√≠ d·ª• text r√°c ·ªü ƒë·∫ßu/cu·ªëi post)
    lines = extract_main_body(lines)
    
    for line in lines:
        line = line.strip()
        if not line:
            continue
            
        # Ki·ªÉm tra xem d√≤ng n√†y c√≥ ph·∫£i ·∫£nh kh√¥ng
        img_match = image_pattern.search(line)
        if img_match:
            img_url = img_match.group(1)
            description = analyze_image_with_gemini(img_url)
            if description:
                labeled_data.append(("IMAGE", description))
        else:
            # X·ª≠ l√Ω Text:
            # 1. Lo·∫°i b·ªè link Markdown, ch·ªâ gi·ªØ text
            clean_line = link_pattern.sub(r'\1', line)
            
            # 2. L·ªçc text r√°c/menu
            if len(clean_line) < 20: 
                continue
                
            # N·∫øu ƒë·∫°t chu·∫©n th√¨ l∆∞u v√†o
            labeled_data.append(("TEXT", clean_line))

    print(f"   -> ƒê√£ x·ª≠ l√Ω xong. T·ªïng s·ªë m·ª•c: {len(labeled_data)}")
    return labeled_data

def analyze_image_with_gemini(img_url, hint=""):
    """T·∫£i ·∫£nh v√† nh·ªù Gemini m√¥ t·∫£. ƒê·ªëi v·ªõi SVG th√¨ tr√≠ch xu·∫•t text."""
    print(f"   Analysing Image: {img_url[:40]}...")
    try:
        # T·∫£i ·∫£nh v·ªÅ
        headers = {'User-Agent': 'Mozilla/5.0'} 
        img_resp = requests.get(img_url, headers=headers, timeout=10)
        
        if img_resp.status_code != 200:
            print(f"   -> L·ªói t·∫£i ·∫£nh: Status {img_resp.status_code}")
            return None

        content_type = img_resp.headers.get('Content-Type', '').lower()
        
        # --- X·ª¨ L√ù RI√äNG CHO SVG ---
        # S·ª≠a logic: Kh√¥ng ch·∫∑n SVG ngay, m√† check n·ªôi dung
        if 'svg' in content_type or img_url.lower().endswith('.svg'):
            try:
                svg_content = img_resp.content.decode('utf-8', errors='ignore')
                root = ET.fromstring(svg_content)
                
                # 1. Check k√≠ch th∆∞·ªõc (Heuristic ƒë∆°n gi·∫£n)
                width = root.get('width')
                height = root.get('height')
                
                def parse_dim(val):
                    if not val: return 0
                    # L·∫•y s·ªë ƒë·∫ßu ti√™n t√¨m th·∫•y
                    nums = re.findall(r'\d+', str(val))
                    return int(nums[0]) if nums else 0

                w_val = parse_dim(width)
                h_val = parse_dim(height)
                
                # N·∫øu c√≥ k√≠ch th∆∞·ªõc v√† c·∫£ 2 ƒë·ªÅu nh·ªè < 150 -> Logo/Icon
                # EXCEPTION: N·∫øu l√† chart trend (hint) th√¨ gi·ªØ l·∫°i
                is_chart_hint = 'trend' in hint or 'chart' in hint
                if not is_chart_hint and w_val > 0 and h_val > 0 and (w_val < 100 or h_val < 100):
                     print(f"   -> B·ªè qua SVG nh·ªè ({w_val}x{h_val})")
                     return None
                
                # 2. Tr√≠ch xu·∫•t Text
                # Namespace th∆∞·ªùng g·∫∑p trong SVG {http://www.w3.org/2000/svg}
                # D√πng .iter() ƒë·ªÉ qu√©t h·∫øt m·ªçi node, l·∫•y .text
                texts = []
                for elem in root.iter():
                    if elem.text and elem.text.strip():
                        texts.append(elem.text.strip())
                
                full_text = " ".join(texts)
                
                # N·∫øu text qu√° ng·∫Øn -> C√≥ th·ªÉ v·∫´n l√† logo d·∫°ng ch·ªØ -> B·ªè qua
                if len(full_text) < 20: 
                    print(f"   -> B·ªè qua SVG √≠t n·ªôi dung ({len(full_text)} chars)")
                    return None
                    
                return f"[SVG TEXT EXTRACTION]: {full_text}"
                
            except Exception as e:
                print(f"   -> L·ªói parse SVG: {e}")
                return None

        # --- X·ª¨ L√ù ·∫¢NH RASTER (JPG/PNG/WEBP) ---
        if not content_type.startswith('image/'):
             # Fallback check extension if content-type is missing/octet-stream
             if not any(x in img_url.lower() for x in ['.jpg', '.png', '.webp', '.jpeg']):
                print(f"   -> B·ªè qua kh√¥ng ph·∫£i ·∫£nh: {content_type}")
                return None

        img_data = Image.open(BytesIO(img_resp.content))
        
        # B·ªè qua ·∫£nh qu√° nh·ªè (icon/logo)
        # EXCEPTION: N·∫øu l√† chart trend (hint) th√¨ gi·ªØ l·∫°i
        is_chart_hint = 'trend' in hint or 'chart' in hint
        if not is_chart_hint and (img_data.size[0] < 150 or img_data.size[1] < 150):
            print(f"   -> B·ªè qua ·∫£nh nh·ªè ({img_data.size}).")
            return None

        prompt = """
ƒê√≥ng vai tr√≤ l√† m·ªôt c√¥ng c·ª• OCR v√† tr√≠ch xu·∫•t d·ªØ li·ªáu th√¥. H√£y ph√¢n t√≠ch h√¨nh ·∫£nh n√†y v√† th·ª±c hi·ªán nhi·ªám v·ª• sau:

1. TR√çCH XU·∫§T: Ghi l·∫°i ch√≠nh x√°c c√°c ƒëo·∫°n vƒÉn b·∫£n (text) v√† c√°c con s·ªë/s·ªë li·ªáu ƒëi k√®m xu·∫•t hi·ªán trong ·∫£nh.
2. ƒê·ªêI V·ªöI BI·ªÇU ƒê·ªí/B·∫¢NG: Ch·ªâ li·ªát k√™ c√°c nh√£n (label) v√† gi√° tr·ªã s·ªë t∆∞∆°ng ·ª©ng (value) m√† b·∫°n nh√¨n th·∫•y r√µ.

TU√ÇN TH·ª¶ NGHI√äM NG·∫∂T C√ÅC QUY T·∫ÆC C·∫§M SAU (NEGATIVE CONSTRAINTS):
- KH√îNG m√¥ t·∫£ c√°c y·∫øu t·ªë th·ªã gi√°c (m√†u s·∫Øc, h√¨nh d√°ng, k√≠ch th∆∞·ªõc, b·ªë c·ª•c, font ch·ªØ, ƒë·ªô s√°ng).
- KH√îNG d√πng c√°c t·ª´ ng·ªØ m√¥ t·∫£ th·∫©m m·ªπ (ƒë·∫πp, x·∫•u, tr·ª±c quan, r√µ r√†ng).
- KH√îNG di·ªÖn gi·∫£i √Ω nghƒ©a, kh√¥ng ph√¢n t√≠ch xu h∆∞·ªõng (v√≠ d·ª•: KH√îNG n√≥i "bi·ªÉu ƒë·ªì cho th·∫•y xu h∆∞·ªõng tƒÉng" hay "l·ª£i nhu·∫≠n r·∫•t t·ªët").
- KH√îNG suy lu·∫≠n nh·ªØng th√¥ng tin kh√¥ng hi·ªÉn th·ªã tr·ª±c ti·∫øp b·∫±ng ch·ªØ ho·∫∑c s·ªë tr√™n ·∫£nh.

ƒê·∫ßu ra ch·ªâ bao g·ªìm d·ªØ li·ªáu vƒÉn b·∫£n v√† s·ªë li·ªáu th√¥."""
        response = model.generate_content([prompt, img_data])
        
        # Track Gemini Usage
        if response.usage_metadata:
            token_usage["gemini"]["in"] += response.usage_metadata.prompt_token_count
            token_usage["gemini"]["out"] += response.usage_metadata.candidates_token_count
            
        return response.text.strip()
    except UnidentifiedImageError:
        print(f"   -> L·ªói: Kh√¥ng nh·∫≠n d·∫°ng ƒë∆∞·ª£c ƒë·ªãnh d·∫°ng ·∫£nh (c√≥ th·ªÉ l√† WebP l·ªói ho·∫∑c file h·ªèng).")
        return None
    except Exception as e:
        print(f"   -> L·ªói x·ª≠ l√Ω ·∫£nh kh√°c: {e}")
        return None # B·ªè qua n·∫øu l·ªói t·∫£i ·∫£nh

def print_token_report():
    print("\n" + "="*40)
    print("üìä B√ÅO C√ÅO TOKEN USAGE")
    print("="*40)
    print(f"üîπ Jina Reader (∆Ø·ªõc l∆∞·ª£ng char):")
    print(f"   - Input : {token_usage['jina']['in']} chars")
    print(f"   - Output: {token_usage['jina']['out']} chars")
    print(f"üîπ Gemini AI (Token ch√≠nh x√°c):")
    print(f"   - Input : {token_usage['gemini']['in']} tokens")
    print(f"   - Output: {token_usage['gemini']['out']} tokens")
    print("="*40 + "\n")



def extract_main_body(lines):
    """
    Heuristic ƒë∆°n gi·∫£n ƒë·ªÉ lo·∫°i b·ªè Header/Footer:
    1. T√¨m 'start_index': D√≤ng ƒë·∫ßu ti√™n c√≥ ƒë·ªô d√†i > 50 k√Ω t·ª± v√† kh√¥ng ph·∫£i l√† link ƒë∆°n thu·∫ßn.
    2. T√¨m 'end_index': D√≤ng cu·ªëi c√πng c√≥ ƒë·ªô d√†i > 50 k√Ω t·ª±.
    3. C·∫Øt b·ªè ph·∫ßn ƒë·∫ßu v√† cu·ªëi ngo√†i kho·∫£ng n√†y, v√¨ th∆∞·ªùng l√† menu/footer links.
    """
    if not lines:
        return []
        
    start_index = 0
    end_index = len(lines)
    
    # 1. Qu√©t t·ª´ tr√™n xu·ªëng t√¨m ƒëi·ªÉm b·∫Øt ƒë·∫ßu n·ªôi dung ch√≠nh
    # B·ªè qua c√°c d√≤ng ng·∫Øn ho·∫∑c d√≤ng ch·ªâ l√† link [text](url)
    for i, line in enumerate(lines):
        line = line.strip()
        is_link = line.startswith('[') and line.endswith(')') and '](' in line
        # Logic m·ªõi: N·∫øu g·∫∑p ·∫¢nh, SVG, ho·∫∑c Table th√¨ coi l√† b·∫Øt ƒë·∫ßu n·ªôi dung ngay
        is_media = '![' in line or '<svg' in line or line.startswith('|')
        
        if (len(line) > 80 and not is_link) or is_media:
            start_index = i
            break
            
    # 2. Qu√©t t·ª´ d∆∞·ªõi l√™n t√¨m ƒëi·ªÉm k·∫øt th√∫c
    for i in range(len(lines) - 1, start_index, -1):
        line = lines[i].strip()
        is_link = line.startswith('[') and line.endswith(')') and '](' in line
        
        # Stop words cho footer
        lower_line = line.lower()
        if "b·∫£n quy·ªÅn" in lower_line or "copyright" in lower_line or "li√™n h·ªá" in lower_line:
            end_index = i
            continue # Ti·∫øp t·ª•c l√πi ƒë·ªÉ c·∫Øt b·ªè d√≤ng n√†y
        
        # Logic m·ªõi: N·∫øu g·∫∑p ·∫¢nh, SVG, ho·∫∑c Table th√¨ coi l√† ph·∫ßn n·ªôi dung, kh√¥ng c·∫Øt
        is_media = '![' in line or '<svg' in line or line.startswith('|')
        
        if (len(line) > 80 and not is_link) or is_media:
            end_index = i + 1 # Gi·ªØ l·∫°i d√≤ng n√†y
            break
            
    # Safety: N·∫øu c·∫Øt qu√° nhi·ªÅu (c√≤n < 10% d√≤ng), c√≥ th·ªÉ heuristics sai -> tr·∫£ v·ªÅ nguy√™n g·ªëc ho·∫∑c fallback
    if end_index - start_index < len(lines) * 0.1:
        print("   -> C·∫£nh b√°o: Heuristics c·∫Øt qu√° nhi·ªÅu, gi·ªØ nguy√™n n·ªôi dung g·ªëc.")
        return lines

    print(f"   -> C·∫Øt Header ({start_index} d√≤ng) v√† Footer ({len(lines)-end_index} d√≤ng).")
    return lines[start_index:end_index]

def process_content_hybrid(url):
    # B∆∞·ªõc 1: L·∫•y Text s·∫°ch t·ª´ Jina
    markdown_content = get_text_from_jina(url)
    if not markdown_content:
        return []

    print("2Ô∏è‚É£  ƒêang x·ª≠ l√Ω n·ªôi dung HTML...")
    
    # Regex Patterns
    # 1. Capture SVGs (Start to End, DOTALL to span lines)
    svg_pattern = re.compile(r'(<svg[^>]*>.*?</svg>)', re.DOTALL | re.IGNORECASE)
    # 2. Capture Img Tags
    img_pattern = re.compile(r'<img[^>]+src=["\'](https?://[^"\']+)["\'][^>]*>', re.IGNORECASE)
    
    labeled_data = [] 

    # --- Step 1: Extract & Process SVGs first (to avoid stripping them) ---
    # We find all SVGs, process them, and then replace them with a placeholder or remove them
    def svg_handler(match):
        svg_content = match.group(1)
        # Check if it's an empty/self-closing SVG tag caught by regex (rare if strictly matched, but safecheck)
        if "viewBox" not in svg_content and len(svg_content) < 100:
             return ""
             
        # Extract text from SVG
        # Simple text extraction: remove tags
        text_content = re.sub(r'<[^>]+>', ' ', svg_content).strip()
        text_content = re.sub(r'\s+', ' ', text_content) # Normalize whitespace
        
        if len(text_content) > 20:
             print(f"   -> Found SVG Chart Data: {text_content[:50]}...")
             labeled_data.append(("CHART_DATA", f"[SVG_EXTRACT]: {text_content}"))
        else:
             print("   -> Found SVG but empty text/data.")
        
        return "" # Remove from main text

    # Apply SVG handler and remove SVGs from content
    content_no_svg = svg_pattern.sub(svg_handler, markdown_content)
    print(f"   -> DEBUG: content_no_svg len: {len(content_no_svg)}")
    with open("debug_content.txt", "w", encoding="utf-8") as f:
        f.write(content_no_svg)

    # --- Step 2: Extract Images ---
    # Improved regex to handle various attribute orders
    # Try a simpler regex first for debugging if the complex one fails
    # img_pattern = re.compile(r'<img[^>]+src=["\'](https?://[^"\']+)["\'][^>]*>', re.IGNORECASE)
    
    # Let's try finding ALL src attributes in img tags roughly
    img_matches = re.finditer(r'<img\s+[^>]*src=["\']([^"\']+)["\']', content_no_svg, re.IGNORECASE)
    
    match_list = list(img_matches)
    print(f"   -> DEBUG block: T√¨m th·∫•y {len(match_list)} th·∫ª img ti·ªÅm nƒÉng.")
    
    for img_match in match_list:
        url = img_match.group(1)
        
        # --- Filter Logic ---
        lower_url = url.lower()
        
        # 1. Skip obvious UI icons/logos UNLESS they are charts
        is_chart = 'trend' in lower_url or 'chart' in lower_url or 'kpi' in lower_url
        if not is_chart and ("icon" in lower_url or "logo" in lower_url or "menu" in lower_url or "btn" in lower_url):
            print(f"      [SKIP-ICON] {url[-20:]}")
            continue
            
        # 2. Skip tracking pixels /ads
        if "delivery/lg.php" in lower_url or "facebook" in lower_url or ".gif" in lower_url:
             print(f"      [SKIP-AD] {url[-20:]}")
             continue
             
        # 3. Handle Relative URLs (Vietstock uses relative paths)
        if not url.startswith('http'):
            # Basic join (assuming base is target_url domain)
            # Just print for now to see if this is the issue
            print(f"      [SKIP-RELATIVE] {url}")
            continue

        print(f"      [PROCESS] Check: {url}")
        description = analyze_image_with_gemini(url, lower_url)
        if description:
             labeled_data.append(("IMAGE", description))
        else:
             print("      [FAIL-GEMINI] Kh√¥ng l·∫•y ƒë∆∞·ª£c m√¥ t·∫£.")

    # --- Step 3: Cleanup Text ---
    # Convert HTML to Text (strip tags) using a regex or simple method
    # Since we don't have BeautifulSoup, we use regex to strip tags
    clean_text = content_no_svg
    # Remove scripts/styles first
    clean_text = re.sub(r'<(script|style)[^>]*>.*?</\1>', '', clean_text, flags=re.DOTALL | re.IGNORECASE)
    # Remove HTML tags
    clean_text = re.sub(r'<[^>]+>', ' ', clean_text) 
    
    lines = clean_text.split('\n')
    # Filter blank lines
    lines = [line.strip() for line in lines if line.strip()]
    
    # Use extract_main_body but be careful not to strip too much if structure is different
    # For now, let's keep it simple: just filter short lines
    
    for line in lines:
        if len(line) < 20 and not line.startswith('|') and not line.startswith('VN-Index'):
            continue
        labeled_data.append(("TEXT", line))

    print(f"   -> ƒê√£ x·ª≠ l√Ω xong. T·ªïng s·ªë m·ª•c: {len(labeled_data)}")
    return labeled_data

def save_file(data):
    filename = "structured_output.txt"
    with open(filename, "w", encoding="utf-8") as f:
        for item_type, content in data:
            # Format: Object - content
            # X·ª≠ l√Ω xu·ªëng d√≤ng trong content ƒë·ªÉ ƒë·∫£m b·∫£o format tr√™n 1 d√≤ng (n·∫øu c·∫ßn) ho·∫∑c gi·ªØ nguy√™n kh·ªëi
            # Y√™u c·∫ßu: "Object - content". ƒê·ªÉ d·ªÖ ƒë·ªçc, c√≥ th·ªÉ cho content n·∫±m c√πng d√≤ng ho·∫∑c ngay sau.
            # ·ªû ƒë√¢y ta s·∫Ω replace newline trong content th√†nh space ƒë·ªÉ ƒë√∫ng format 1 d√≤ng logic
            clean_content = content.replace('\n', ' ').strip()
            f.write(f"{item_type} - {clean_content}\n")
            
    print(f"\n‚úÖ Xong! K·∫øt qu·∫£ l∆∞u t·∫°i: {filename}")

# --- CH·∫†Y ---
if __name__ == "__main__":
    url_input = input("\nNhap URL bai viet can xu ly: ").strip()
    # url_input = "https://finance.vietstock.vn/"
    
    if not url_input:
        print("‚ùå Vui l√≤ng nh·∫≠p URL h·ª£p l·ªá!")
    else:
        result = process_content_hybrid(url_input)
        if result:
            save_file(result)
        print_token_report()
